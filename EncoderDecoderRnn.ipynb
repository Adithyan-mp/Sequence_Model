{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHskwrVLFARzJTsWUC75SW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adithyan-mp/Sequence_Model/blob/main/EncoderDecoderRnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIg-30CihJ36",
        "outputId": "4224b4fb-0eef-4185-8067-c87a236d2340"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "XSQuOYdD6sdC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.optim import adam\n",
        "from nltk import word_tokenize\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/eng_-french.csv')\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "DJaywS9280vi",
        "outputId": "286220af-b320-43a1-e6b2-aebb98e36195"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  English words/sentences  \\\n",
              "175616  Top-down economics never works, said Obama. \"T...   \n",
              "175617  A carbon footprint is the amount of carbon dio...   \n",
              "175618  Death is something that we're often discourage...   \n",
              "175619  Since there are usually multiple websites on a...   \n",
              "175620  If someone who doesn't know your background sa...   \n",
              "\n",
              "                                   French words/sentences  \n",
              "175616  « L'économie en partant du haut vers le bas, ç...  \n",
              "175617  Une empreinte carbone est la somme de pollutio...  \n",
              "175618  La mort est une chose qu'on nous décourage sou...  \n",
              "175619  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "175620  Si quelqu'un qui ne connaît pas vos antécédent...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ef133f2-2c08-45c7-98ad-70bfe8733681\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English words/sentences</th>\n",
              "      <th>French words/sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175616</th>\n",
              "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
              "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175617</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175618</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175619</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175620</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ef133f2-2c08-45c7-98ad-70bfe8733681')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ef133f2-2c08-45c7-98ad-70bfe8733681 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ef133f2-2c08-45c7-98ad-70bfe8733681');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2a0078c-fb8d-4ee2-af35-ec2e06bdbed4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2a0078c-fb8d-4ee2-af35-ec2e06bdbed4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2a0078c-fb8d-4ee2-af35-ec2e06bdbed4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"English words/sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\",\n          \"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\",\n          \"Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"French words/sentences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Une empreinte carbone est la somme de pollution au dioxyde de carbone que nous produisons par nos activit\\u00e9s. Certaines personnes essaient de r\\u00e9duire leur empreinte carbone parce qu'elles sont inqui\\u00e8tes du changement climatique.\",\n          \"Si quelqu'un qui ne conna\\u00eet pas vos ant\\u00e9c\\u00e9dents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqu\\u00e9 quelque chose \\u00e0 propos de votre \\u00e9locution qui lui a fait prendre conscience que vous n'\\u00eates pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\",\n          \"La mort est une chose qu'on nous d\\u00e9courage souvent de discuter ou m\\u00eame de penser mais j'ai pris conscience que se pr\\u00e9parer \\u00e0 la mort est l'une des choses que nous puissions faire qui nous investit le plus de responsabilit\\u00e9. R\\u00e9fl\\u00e9chir \\u00e0 la mort clarifie notre vie.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n",
        "print(f\" \\n null value : {df.isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "widIS50r95sF",
        "outputId": "04d471fd-dd2b-4a4c-cf50-5b0054ce2f1f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 175621 entries, 0 to 175620\n",
            "Data columns (total 2 columns):\n",
            " #   Column                   Non-Null Count   Dtype \n",
            "---  ------                   --------------   ----- \n",
            " 0   English words/sentences  175621 non-null  object\n",
            " 1   French words/sentences   175621 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 2.7+ MB\n",
            "None\n",
            " \n",
            " null value : English words/sentences    0\n",
            "French words/sentences     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df['English words/sentences'][:500]\n",
        "y=df['French words/sentences'][:500]\n",
        "print(f\"length of the feature {len(x)}\")\n",
        "print(f\"length of the target {len(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5lggKzt-MA9",
        "outputId": "639304c2-4891-42c6-99f5-712f981a0b6e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of the feature 500\n",
            "length of the target 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_tokenized_list = [word_tokenize(word) for word in x]\n",
        "print(x_tokenized_list[0:5])\n",
        "y_tokenized_list = [word_tokenize(word) for word in y]\n",
        "print(y_tokenized_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoyYxmUag7Ag",
        "outputId": "c15eaee7-ff7b-4696-e1b0-ebf3bc4db598"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Hi', '.'], ['Run', '!'], ['Run', '!'], ['Who', '?'], ['Wow', '!']]\n",
            "[['Salut', '!'], ['Cours', '!'], ['Courez', '!'], ['Qui', '?'], ['Ça', 'alors', '!']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    x_batch, y_batch = zip(*batch)  # Unzip list of tuples\n",
        "    x_batch = [torch.tensor(x, dtype=torch.long) for x in x_batch]\n",
        "    y_batch = [torch.tensor(y, dtype=torch.long) for y in y_batch]\n",
        "\n",
        "    x_padded = pad_sequence(x_batch, batch_first=True, padding_value=0)\n",
        "    y_padded = pad_sequence(y_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return x_padded, y_padded\n",
        "\n",
        "def get_vocab(x_tokenized_list,y_tokenized_list):\n",
        "\n",
        "  x_tokenized = pd.Series([token for lists in x_tokenized_list for token in lists])\n",
        "  y_tokenized = pd.Series([token for lists in y_tokenized_list for token in lists])\n",
        "  count_x = x_tokenized.value_counts(ascending=False)\n",
        "  count_y = y_tokenized.value_counts(ascending=False)\n",
        "  source_vocab = {key:idx+4 for idx,(key,value) in enumerate(count_x.items()) if idx<100000}\n",
        "  target_vocab = {key:idx+4 for idx,(key,value) in enumerate(count_y.items()) if idx<100000}\n",
        "  source_vocab = {'<PAD>':0,'<EOS>':1,\"<SOS>\":2,\"<UNK>\":3,**source_vocab}\n",
        "  target_vocab = {'<PAD>':0,'<EOS>':1,\"<SOS>\":2,\"<UNK>\":3,**target_vocab}\n",
        "\n",
        "  return source_vocab,target_vocab\n",
        "\n",
        "def get_dataset(source_vocab,target_vocab,x_tokenized_list,y_tokenized_list):\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for lists in x_tokenized_list :\n",
        "    temp = []\n",
        "    for token in lists:\n",
        "      temp.append(source_vocab.get(token.lower(),source_vocab['<UNK>']))\n",
        "    temp.append(source_vocab['<EOS>'])\n",
        "    x.append(temp)\n",
        "\n",
        "  for lists in y_tokenized_list :\n",
        "    temp = []\n",
        "    temp.append(target_vocab['<SOS>'])\n",
        "    for token in lists:\n",
        "      temp.append(target_vocab.get(token.lower(),target_vocab['<UNK>']))\n",
        "    temp.append(target_vocab['<EOS>'])\n",
        "    y.append(temp)\n",
        "  return x,y\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,x,y,transform=None) -> None:\n",
        "    super().__init__()\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.transform = transform\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self, index) :\n",
        "    x_i,y_i = self.x[index],self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      x_i = self.transform(x_i)\n",
        "      y_i = self.transform(y_i)\n",
        "    return x_i,y_i\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self, array) :\n",
        "    return torch.tensor(array,dtype=torch.long)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size=100000, embedding_dim=300, hidden_size=100):\n",
        "        super().__init__()\n",
        "        self.embed_layer = nn.Embedding(vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size, _ = input.size()\n",
        "        device = input.device  # ensure tensor compatibility\n",
        "        embedded = self.embed_layer(input)\n",
        "        h0 = torch.zeros((1, batch_size, 100), device=device)  # move to same device\n",
        "        _, hn = self.rnn(embedded, h0)\n",
        "        return hn  # shape: [1, batch_size, hidden]\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size=100000, embedding_dim=300, hidden_size=100):\n",
        "        super().__init__()\n",
        "        self.embed_layer = nn.Embedding(vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, hn_e, max_len=20, return_logits=False):\n",
        "        batch_size = hn_e.size(1)\n",
        "        device = hn_e.device\n",
        "        input = torch.full((batch_size, 1), 2, dtype=torch.long, device=device)  # 2 = <SOS>\n",
        "        outputs = []\n",
        "        logits_list = []\n",
        "        hn = hn_e\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            # [batch_size, 1, embedding_dim]\n",
        "            # out: [batch_size, 1, hidden]\n",
        "            # logits: [batch_size, 1, vocab_size]\n",
        "            # [batch_size, 1]\n",
        "\n",
        "            embedded = self.embed_layer(input)\n",
        "            out, hn = self.rnn(embedded, hn)\n",
        "            logits = self.fc_out(out)\n",
        "            pred = torch.argmax(logits, dim=2)\n",
        "\n",
        "            logits_list.append(logits)\n",
        "            outputs.append(pred)\n",
        "            input = pred\n",
        "\n",
        "            if torch.all(pred == 1):  # 1 = <EOS>\n",
        "                break\n",
        "\n",
        "        if return_logits:\n",
        "            return torch.cat(logits_list, dim=1)  # shape: [batch_size, max_len, vocab_size]\n",
        "        else:\n",
        "            return torch.cat(outputs, dim=1)      # shape: [batch_size, max_len]\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, input, return_logits=False):\n",
        "        hn = self.encoder(input)\n",
        "        output = self.decoder(hn, return_logits=return_logits)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "4xRzPaiCk2Su"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Assuming you already have tokenized input/output lists\n",
        "# x_tokenized_list = [...]\n",
        "# y_tokenized_list = [...]\n",
        "\n",
        "source_vocab, target_vocab = get_vocab(x_tokenized_list, y_tokenized_list)\n",
        "x, y = get_dataset(source_vocab, target_vocab, x_tokenized_list, y_tokenized_list)\n",
        "\n",
        "transform = ToTensor()\n",
        "dataset = CustomDataset(x, y, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vocab_size = len(target_vocab)\n",
        "\n",
        "model = Model().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=0)  # Ignore <PAD>\n",
        "\n",
        "\n",
        "def train(model, dataloader, optimizer, loss_fn, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x_batch, return_logits=True)  # [batch, seq_len, vocab]\n",
        "\n",
        "\n",
        "            # Match shapes for loss\n",
        "            if output.size(1) < y_batch.size(1):\n",
        "                pad = torch.full((output.size(0), y_batch.size(1) - output.size(1),100000), 0, dtype=torch.float, device=device)\n",
        "                output = torch.cat([output, pad], dim=1)\n",
        "            elif output.size(1) > y_batch.size(1):\n",
        "                output = output[:, :y_batch.size(1),:]\n",
        "                # print(output.size())\n",
        "\n",
        "            output = output.reshape(-1, output.size(-1))  # shape: [batch_size * sequence_len, vocab_size]\n",
        "            y_batch = y_batch.view(-1)                    # [batch * seq_len]\n",
        "            loss = loss_fn(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "train(model, dataloader, optimizer, loss_fn, num_epochs=10)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mwtCBptmn12g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c47bc7-b30d-4d3e-9cea-d3bce6e65d2d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-3888350809>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_batch = [torch.tensor(x, dtype=torch.long) for x in x_batch]\n",
            "<ipython-input-49-3888350809>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_batch = [torch.tensor(y, dtype=torch.long) for y in y_batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 10.0941\n",
            "Epoch 2, Loss: 7.4926\n",
            "Epoch 3, Loss: 5.3778\n",
            "Epoch 4, Loss: 5.3240\n",
            "Epoch 5, Loss: 4.7210\n",
            "Epoch 6, Loss: 4.8924\n",
            "Epoch 7, Loss: 4.5330\n",
            "Epoch 8, Loss: 4.4796\n",
            "Epoch 9, Loss: 4.4701\n",
            "Epoch 10, Loss: 4.4333\n"
          ]
        }
      ]
    }
  ]
}